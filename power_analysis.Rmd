---
title: "MB3 Power Analysis"
author: "George & Angeline"
date: "10/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
library(lmerTest)
```

## Design


For this power analysis we will simulate 20 labs contributing 16 infants (320 participants) from 5 to 12 months of age.

Factors:

* *familiarized_rule*: indicates the sequence to which infants were exposed during familiarization (ABA or ABB). Infants were exposed to only one sequence, with the sequence determined by random assignment. (GK: not counterbalanced per lab?)

* *trial_type*: indicates whether each test sequence followed the same rule to which the infant was familiarized or a different rule. For example, if an infant heard an ABA rule during familiarization, ABA trials would be the *same* trial type and ABB trials would be the *different* trial type (each infant get 6 of same and 6 different)

* *trial_num*: indicates the sequential order in which test trials were presented. Trial number thus ranges from 1 to 12. 

* *age_mos*: the infants' age in months (5.0-12.0), centered in *age* column.

* *procedure*: indicates the experimental method that was used to record infantsâ€™ responses to the stimuli: headturn preference procedure (HPP), central fixation (CF), or eye tracking (ET). 
* *test_order*: indicates which of the four pseudorandom test orders (from our provided scripts) were used to present test trials to the infant. 

* *multilingual_exposure*: indicates the infants' exposure to the secondary/primary language, ranging from 0% (no exposure to a secondary language) to 49% (i.e., baby hears 51% of their primary language and 49% of the secondary language). 

To do our power analysis, we will generate 100 datasets of this structure with a given effect size (e.g., .3), run the mixed-effects regression for each simulated dataset, and count the number of times that the effect is significant.

## Simulate Datasets

```{r simulate-data}
set.seed(123) # reproducible sampling

generate_dataset <- function(n_labs=20, n_per_lab=16, effect_size=.3) {
  # rewrite to use expand.grid ?
  labID = rep(LETTERS[1:n_labs], each=n_per_lab)
  subjID = 1:(n_labs*n_per_lab)

  # assume each lab uses one procedure
  lab_procedure = sample(c("HPP","CF","EF"), n_labs, replace=T, prob=c(.5,.3,.2))
  procedure = rep(lab_procedure, each=n_per_lab)

  test_order = rep(1:4, 4*n_labs) 

  # familiarized rule (ms says randomly assigned: we don't want counterbalanced per lab?)
  familiarized_rule = sample(c("ABB","ABA"), length(subjID), replace=T)

  simd <- tibble(subjID, labID, procedure, test_order, familiarized_rule)

  # uniform random vars
  simd$age_mos = runif(nrow(simd), min=5.0, max=12.0)
  simd$age = scale(simd$age_mos, center=T, scale=F)[,1]

  # should actually be bimodal (use MB1 distro?)
  simd$multilingual_exposure = runif(nrow(simd), min=0, max=.5) # 0=monolingual, .5=50% secondary language

  # now generate looking times for 12 trials per subject
  for(t in 1:12) {
    simd[,paste0("trial.",t)] = rnorm(n = nrow(simd), mean=0, sd=1) # = .05
  } 
  
  # USE LOG-NORMAL DISTRIBUTION? IF SO, NEED TO SCALE EFFECT SIZE
  #for(t in 1:12) {
  #  simd[,paste0("trial.",t)] = rlnorm(n = nrow(simd), 
  #                 meanlog = log((10^2) / sqrt(0.5^2 + 10^2)), # = 2.3
  #                 sdlog = sqrt(log(1 + (0.5^2 / 10^2)))) # = .05
  #} #say raw LT mean = 10, raw LT SD = 1
  
  
  siml <- simd %>% pivot_longer(cols=starts_with("trial."), 
                     names_to="trial_num", 
                     names_prefix="trial.",
                     values_to="looking_time") 

  siml$trial_num = as.numeric(siml$trial_num)

  # 6 same / 6 different per child; should be according to 1 of 4 pseudorandom orders, but we're not   actually modeling order effects here so just make blocks:
  siml$trial_type = rep_len(c(rep("same", 6), rep("different", 6)), nrow(siml)) # each

  per_subj_trial_type = c(rep("same", 6), rep("different", 6))
  siml$subjInt = 0.0
  for(s in 1:length(unique(siml$subjID))) {
    subjInd = which(siml$subjID==s)
    siml[subjInd,]$trial_type = sample(per_subj_trial_type, 12, replace = F)
    siml[subjInd,]$subjInt = rnorm(1, mean=0, sd=1)
  }

# what effects do we want to simulate?
# minimally, when trial_type=="same" looking times should be longer
# maybe this effect gets stronger with age, and/or stronger with multilingual_exposure
  # .25 in meta-analysis
  inds_to_shift = which(siml$trial_type=="same")
  siml[inds_to_shift,]$looking_time = rnorm(length(inds_to_shift), mean=effect_size, sd=1) + 
    siml[inds_to_shift,]$subjInt
  siml$subjID = as.factor(siml$subjID)
  return(siml)
}

```

## Plot Example Dataset

```{r}
siml = generate_dataset(effect_size=.3)

dag <- siml %>% group_by(subjID, trial_type, trial_num) %>%
  tidyboot::tidyboot_mean(looking_time) # quite slow..

ggplot(dag, aes(x=trial_num, y=mean, group=trial_type, color=trial_type)) + 
    geom_point(aes(y=mean, x=jitter(trial_num)), alpha=.2) + 
    geom_linerange(aes(ymin=ci_lower, ymax=ci_upper)) + 
    theme_bw()
```


## Model Structure

Infants' looking time (DV) ~ 1+ familiarization order (ABB vs ABA) * trial_type + age * trial_type (same rule vs different rule at test) + experimental_method (HPP vs central fixation vs eye-tracking) * trial_type + multilingual_exposure * trial_type + trial_num * trial_type + (trial_num*trial_type | subject) + (test_order | lab)

```{r model, echo=FALSE}
#m1 <- glmer(z ~ x + (1|g), family="poisson", data=simdata)
# m1 <- lmer(looking_time ~ 1 + trial_type * 
#              (familiarized_rule + age + procedure + multilingual_exposure + trial_num) +
#              (trial_num * trial_type | subjID) + (test_order | labID), data=siml)

fit_model <- function(siml) {
  m_simple <- lmer(looking_time ~ 1 + trial_type * trial_num + (1 | subjID), data=siml)
  return(summary(m_simple)$coefficients["trial_typesame","Pr(>|t|)"]) # "Estimate","t value",
}

```

## Power Analysis

To do the power analysis, we simply generate 1000 datasets with a main effect (size = 0.3) of trial type, run the above linear mixed-effects model, and report how many times the trial type effect is significant,

```{r, power-analysis}
# repeatedly generate data and  significance of trial_typesame
get_power <- function(effect_size, N=100, alpha=.05) {
  p = rep(NA, N)
  for(i in 1:N) {
    p[i] = fit_model(generate_dataset(effect_size=effect_size))
  }
  print(paste(length(which(p<alpha)), "of",N, "simulations had p <",alpha))
  return(p)
}

pvalues = get_power(effect_size=0.3, N=1000)
```

The trial type effect was significant ($p<.05$) in `r length(which(pvalues<0.05))` of the 1000 simulations.

